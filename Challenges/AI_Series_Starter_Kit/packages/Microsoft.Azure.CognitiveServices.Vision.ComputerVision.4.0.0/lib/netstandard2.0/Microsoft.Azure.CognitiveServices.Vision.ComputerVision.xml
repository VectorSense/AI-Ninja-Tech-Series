<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.Azure.CognitiveServices.Vision.ComputerVision</name>
    </assembly>
    <members>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ApiKeyServiceClientCredentials">
            <summary>
            Allows authentication to the API using a basic apiKey mechanism
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ApiKeyServiceClientCredentials.#ctor(System.String)">
            <summary>
            Creates a new instance of the ApiKeyServiceClientCredentails class
            </summary>
            <param name="subscriptionKey">The subscription key to authenticate and authorize as</param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ApiKeyServiceClientCredentials.ProcessHttpRequestAsync(System.Net.Http.HttpRequestMessage,System.Threading.CancellationToken)">
            <summary>
            Add the Basic Authentication Header to each outgoing request
            </summary>
            <param name="request">The outgoing request</param>
            <param name="cancellationToken">A token to cancel the operation</param>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient">
            <summary>
            The Computer Vision API provides state-of-the-art algorithms to process
            images and return information. For example, it can be used to determine
            if an image contains mature content, or it can be used to find all the
            faces in an image.  It also has other features like estimating dominant
            and accent colors, categorizing the content of images, and describing
            an image with complete English sentences.  Additionally, it can also
            intelligently generate images thumbnails for displaying large images
            effectively.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.BaseUri">
            <summary>
            The base URI of the service.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.SerializationSettings">
            <summary>
            Gets or sets json serialization settings.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.DeserializationSettings">
            <summary>
            Gets or sets json deserialization settings.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.Endpoint">
            <summary>
            Supported Cognitive Services endpoints.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.Credentials">
            <summary>
            Subscription credentials which uniquely identify client subscription.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.#ctor(System.Net.Http.HttpClient,System.Boolean)">
            <summary>
            Initializes a new instance of the ComputerVisionClient class.
            </summary>
            <param name='httpClient'>
            HttpClient to be used
            </param>
            <param name='disposeHttpClient'>
            True: will dispose the provided httpClient on calling ComputerVisionClient.Dispose(). False: will not dispose provided httpClient</param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.#ctor(System.Net.Http.DelegatingHandler[])">
            <summary>
            Initializes a new instance of the ComputerVisionClient class.
            </summary>
            <param name='handlers'>
            Optional. The delegating handlers to add to the http client pipeline.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.#ctor(System.Net.Http.HttpClientHandler,System.Net.Http.DelegatingHandler[])">
            <summary>
            Initializes a new instance of the ComputerVisionClient class.
            </summary>
            <param name='rootHandler'>
            Optional. The http client handler used to handle http transport.
            </param>
            <param name='handlers'>
            Optional. The delegating handlers to add to the http client pipeline.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.#ctor(Microsoft.Rest.ServiceClientCredentials,System.Net.Http.DelegatingHandler[])">
            <summary>
            Initializes a new instance of the ComputerVisionClient class.
            </summary>
            <param name='credentials'>
            Required. Subscription credentials which uniquely identify client subscription.
            </param>
            <param name='handlers'>
            Optional. The delegating handlers to add to the http client pipeline.
            </param>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.#ctor(Microsoft.Rest.ServiceClientCredentials,System.Net.Http.HttpClient,System.Boolean)">
            <summary>
            Initializes a new instance of the ComputerVisionClient class.
            </summary>
            <param name='credentials'>
            Required. Subscription credentials which uniquely identify client subscription.
            </param>
            <param name='httpClient'>
            HttpClient to be used
            </param>
            <param name='disposeHttpClient'>
            True: will dispose the provided httpClient on calling ComputerVisionClient.Dispose(). False: will not dispose provided httpClient</param>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.#ctor(Microsoft.Rest.ServiceClientCredentials,System.Net.Http.HttpClientHandler,System.Net.Http.DelegatingHandler[])">
            <summary>
            Initializes a new instance of the ComputerVisionClient class.
            </summary>
            <param name='credentials'>
            Required. Subscription credentials which uniquely identify client subscription.
            </param>
            <param name='rootHandler'>
            Optional. The http client handler used to handle http transport.
            </param>
            <param name='handlers'>
            Optional. The delegating handlers to add to the http client pipeline.
            </param>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.Initialize">
            <summary>
            Initializes client properties.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.AnalyzeImageWithHttpMessagesAsync(System.String,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Details},System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation extracts a rich set of visual features based on the image
            content.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL. Within your request, there is an optional parameter to allow
            you to choose which features to return. By default, image categories are
            returned in the response.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='visualFeatures'>
            A string indicating what visual feature types to return. Multiple values
            should be comma-separated. Valid visual feature types include: Categories -
            categorizes image content according to a taxonomy defined in documentation.
            Tags - tags the image with a detailed list of words related to the image
            content. Description - describes the image content with a complete English
            sentence. Faces - detects if faces are present. If present, generate
            coordinates, gender and age. ImageType - detects if image is clipart or a
            line drawing. Color - determines the accent color, dominant color, and
            whether an image is black&amp;white. Adult - detects if the image is
            pornographic in nature (depicts nudity or a sex act).  Sexually suggestive
            content is also detected. Objects - detects various objects within an
            image, including the approximate location. The Objects argument is only
            available in English. Brands - detects various brands within an image,
            including the approximate location. The Brands argument is only available
            in English.
            </param>
            <param name='details'>
            A string indicating which domain-specific details to return. Multiple
            values should be comma-separated. Valid visual feature types include:
            Celebrities - identifies celebrities if detected in the image, Landmarks -
            identifies notable landmarks in the image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.DescribeImageWithHttpMessagesAsync(System.String,System.Nullable{System.Int32},System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a description of an image in human readable
            language with complete sentences. The description is based on a collection
            of content tags, which are also returned by the operation. More than one
            description can be generated for each image. Descriptions are ordered by
            their confidence score. All descriptions are in English.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='maxCandidates'>
            Maximum number of candidate descriptions to be returned.  The default is 1.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.DetectObjectsWithHttpMessagesAsync(System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Performs object detection on the specified image.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.ListModelsWithHttpMessagesAsync(System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation returns the list of domain-specific models that are
            supported by the Computer Vision API. Currently, the API supports following
            domain-specific models: celebrity recognizer, landmark recognizer.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.AnalyzeImageByDomainWithHttpMessagesAsync(System.String,System.String,System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation recognizes content within an image by applying a
            domain-specific model. The list of domain-specific models that are
            supported by the Computer Vision API can be retrieved using the /models GET
            request. Currently, the API provides following domain-specific models:
            celebrities, landmarks.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON.
            If the request failed, the response will contain an error code and a
            message to help understand what went wrong.
            </summary>
            <param name='model'>
            The domain-specific content to recognize.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.RecognizePrintedTextWithHttpMessagesAsync(System.Boolean,System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLanguages,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Optical Character Recognition (OCR) detects text in an image and extracts
            the recognized characters into a machine-usable character stream.
            Upon success, the OCR results will be returned.
            Upon failure, the error code together with an error message will be
            returned. The error code can be one of InvalidImageUrl, InvalidImageFormat,
            InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or
            InternalServerError.
            </summary>
            <param name='detectOrientation'>
            Whether detect the text orientation in the image. With
            detectOrientation=true the OCR service tries to detect the image
            orientation and correct it before further processing (e.g. if it's
            upside-down).
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The BCP-47 language code of the text to be detected in the image. The
            default value is 'unk'. Possible values include: 'unk', 'zh-Hans',
            'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it',
            'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro',
            'sr-Cyrl', 'sr-Latn', 'sk'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.TagImageWithHttpMessagesAsync(System.String,System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a list of words, or tags, that are relevant to the
            content of the supplied image. The Computer Vision API can return tags
            based on objects, living beings, scenery or actions found in images. Unlike
            categories, tags are not organized according to a hierarchical
            classification system, but correspond to image content. Tags may contain
            hints to avoid ambiguity or provide context, for example the tag "cello"
            may be accompanied by the hint "musical instrument". All tags are in
            English.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.GenerateThumbnailWithHttpMessagesAsync(System.Int32,System.Int32,System.String,System.Nullable{System.Boolean},System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a thumbnail image with the user-specified width
            and height. By default, the service analyzes the image, identifies the
            region of interest (ROI), and generates smart cropping coordinates based on
            the ROI. Smart cropping helps when you specify an aspect ratio that differs
            from that of the input image.
            A successful response contains the thumbnail image binary. If the request
            failed, the response contains an error code and a message to help determine
            what went wrong.
            Upon failure, the error code and an error message are returned. The error
            code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
            InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or
            InternalServerError.
            </summary>
            <param name='width'>
            Width of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='height'>
            Height of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='smartCropping'>
            Boolean flag for enabling smart cropping.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Rest.HttpOperationException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.GetAreaOfInterestWithHttpMessagesAsync(System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation returns a bounding box around the most important area of the
            image.
            A successful response will be returned in JSON. If the request failed, the
            response contains an error code and a message to help determine what went
            wrong.
            Upon failure, the error code and an error message are returned. The error
            code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
            NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.RecognizeTextWithHttpMessagesAsync(System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Recognize Text operation. When you use the Recognize Text interface, the
            response contains a field called 'Operation-Location'. The
            'Operation-Location' field contains the URL that you must use for your Get
            Recognize Text Operation Result operation.
            </summary>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.GetTextOperationResultWithHttpMessagesAsync(System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This interface is used for getting text operation result. The URL to this
            interface should be retrieved from 'Operation-Location' field returned from
            Recognize Text interface.
            </summary>
            <param name='operationId'>
            Id of the text operation returned in the response of the 'Recognize Text'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.BatchReadFileWithHttpMessagesAsync(System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Use this interface to get the result of a Read operation, employing the
            state-of-the-art Optical Character Recognition (OCR) algorithms optimized
            for text-heavy documents. When you use the Read File interface, the
            response contains a field called "Operation-Location". The
            "Operation-Location" field contains the URL that you must use for your
            "Read Operation Result" operation to access OCR results.â€‹
            </summary>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.GetReadOperationResultWithHttpMessagesAsync(System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This interface is used for getting OCR results of Read operation. The URL
            to this interface should be retrieved from "Operation-Location" field
            returned from Batch Read File interface.
            </summary>
            <param name='operationId'>
            Id of read operation returned in the response of the "Batch Read File"
            interface.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.AnalyzeImageInStreamWithHttpMessagesAsync(System.IO.Stream,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Details},System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation extracts a rich set of visual features based on the image
            content.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL. Within your request, there is an optional parameter to allow
            you to choose which features to return. By default, image categories are
            returned in the response.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='visualFeatures'>
            A string indicating what visual feature types to return. Multiple values
            should be comma-separated. Valid visual feature types include: Categories -
            categorizes image content according to a taxonomy defined in documentation.
            Tags - tags the image with a detailed list of words related to the image
            content. Description - describes the image content with a complete English
            sentence. Faces - detects if faces are present. If present, generate
            coordinates, gender and age. ImageType - detects if image is clipart or a
            line drawing. Color - determines the accent color, dominant color, and
            whether an image is black&amp;white. Adult - detects if the image is
            pornographic in nature (depicts nudity or a sex act).  Sexually suggestive
            content is also detected. Objects - detects various objects within an
            image, including the approximate location. The Objects argument is only
            available in English. Brands - detects various brands within an image,
            including the approximate location. The Brands argument is only available
            in English.
            </param>
            <param name='details'>
            A string indicating which domain-specific details to return. Multiple
            values should be comma-separated. Valid visual feature types include:
            Celebrities - identifies celebrities if detected in the image, Landmarks -
            identifies notable landmarks in the image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.GetAreaOfInterestInStreamWithHttpMessagesAsync(System.IO.Stream,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation returns a bounding box around the most important area of the
            image.
            A successful response will be returned in JSON. If the request failed, the
            response contains an error code and a message to help determine what went
            wrong.
            Upon failure, the error code and an error message are returned. The error
            code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
            NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.DescribeImageInStreamWithHttpMessagesAsync(System.IO.Stream,System.Nullable{System.Int32},System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a description of an image in human readable
            language with complete sentences. The description is based on a collection
            of content tags, which are also returned by the operation. More than one
            description can be generated for each image. Descriptions are ordered by
            their confidence score. All descriptions are in English.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='maxCandidates'>
            Maximum number of candidate descriptions to be returned.  The default is 1.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.DetectObjectsInStreamWithHttpMessagesAsync(System.IO.Stream,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Performs object detection on the specified image.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.GenerateThumbnailInStreamWithHttpMessagesAsync(System.Int32,System.Int32,System.IO.Stream,System.Nullable{System.Boolean},System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a thumbnail image with the user-specified width
            and height. By default, the service analyzes the image, identifies the
            region of interest (ROI), and generates smart cropping coordinates based on
            the ROI. Smart cropping helps when you specify an aspect ratio that differs
            from that of the input image.
            A successful response contains the thumbnail image binary. If the request
            failed, the response contains an error code and a message to help determine
            what went wrong.
            Upon failure, the error code and an error message are returned. The error
            code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
            InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or
            InternalServerError.
            </summary>
            <param name='width'>
            Width of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='height'>
            Height of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='smartCropping'>
            Boolean flag for enabling smart cropping.
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Rest.HttpOperationException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.AnalyzeImageByDomainInStreamWithHttpMessagesAsync(System.String,System.IO.Stream,System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation recognizes content within an image by applying a
            domain-specific model. The list of domain-specific models that are
            supported by the Computer Vision API can be retrieved using the /models GET
            request. Currently, the API provides following domain-specific models:
            celebrities, landmarks.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON.
            If the request failed, the response will contain an error code and a
            message to help understand what went wrong.
            </summary>
            <param name='model'>
            The domain-specific content to recognize.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.RecognizePrintedTextInStreamWithHttpMessagesAsync(System.Boolean,System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLanguages,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Optical Character Recognition (OCR) detects text in an image and extracts
            the recognized characters into a machine-usable character stream.
            Upon success, the OCR results will be returned.
            Upon failure, the error code together with an error message will be
            returned. The error code can be one of InvalidImageUrl, InvalidImageFormat,
            InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or
            InternalServerError.
            </summary>
            <param name='detectOrientation'>
            Whether detect the text orientation in the image. With
            detectOrientation=true the OCR service tries to detect the image
            orientation and correct it before further processing (e.g. if it's
            upside-down).
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The BCP-47 language code of the text to be detected in the image. The
            default value is 'unk'. Possible values include: 'unk', 'zh-Hans',
            'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it',
            'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro',
            'sr-Cyrl', 'sr-Latn', 'sk'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.TagImageInStreamWithHttpMessagesAsync(System.IO.Stream,System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a list of words, or tags, that are relevant to the
            content of the supplied image. The Computer Vision API can return tags
            based on objects, living beings, scenery or actions found in images. Unlike
            categories, tags are not organized according to a hierarchical
            classification system, but correspond to image content. Tags may contain
            hints to avoid ambiguity or provide context, for example the tag "cello"
            may be accompanied by the hint "musical instrument". All tags are in
            English.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.SerializationException">
            Thrown when unable to deserialize the response
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.RecognizeTextInStreamWithHttpMessagesAsync(System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Recognize Text operation. When you use the Recognize Text interface, the
            response contains a field called 'Operation-Location'. The
            'Operation-Location' field contains the URL that you must use for your Get
            Recognize Text Operation Result operation.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClient.BatchReadFileInStreamWithHttpMessagesAsync(System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Use this interface to get the result of a Read Document operation,
            employing the state-of-the-art Optical Character Recognition (OCR)
            algorithms optimized for text-heavy documents. When you use the Read
            Document interface, the response contains a field called
            "Operation-Location". The "Operation-Location" field contains the URL that
            you must use for your "Get Read Result operation" to access OCR results.â€‹
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='customHeaders'>
            Headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
            <exception cref="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            Thrown when the operation returned an invalid status code
            </exception>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown when a required parameter is null
            </exception>
            <exception cref="T:System.ArgumentNullException">
            Thrown when a required parameter is null
            </exception>
            <return>
            A response object containing the response body and response headers.
            </return>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions">
            <summary>
            Extension methods for ComputerVisionClient.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.AnalyzeImageAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Details},System.String,System.Threading.CancellationToken)">
            <summary>
            This operation extracts a rich set of visual features based on the image
            content.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL. Within your request, there is an optional parameter to allow
            you to choose which features to return. By default, image categories are
            returned in the response.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='visualFeatures'>
            A string indicating what visual feature types to return. Multiple values
            should be comma-separated. Valid visual feature types include: Categories -
            categorizes image content according to a taxonomy defined in documentation.
            Tags - tags the image with a detailed list of words related to the image
            content. Description - describes the image content with a complete English
            sentence. Faces - detects if faces are present. If present, generate
            coordinates, gender and age. ImageType - detects if image is clipart or a
            line drawing. Color - determines the accent color, dominant color, and
            whether an image is black&amp;white. Adult - detects if the image is
            pornographic in nature (depicts nudity or a sex act).  Sexually suggestive
            content is also detected. Objects - detects various objects within an
            image, including the approximate location. The Objects argument is only
            available in English. Brands - detects various brands within an image,
            including the approximate location. The Brands argument is only available
            in English.
            </param>
            <param name='details'>
            A string indicating which domain-specific details to return. Multiple
            values should be comma-separated. Valid visual feature types include:
            Celebrities - identifies celebrities if detected in the image, Landmarks -
            identifies notable landmarks in the image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.DescribeImageAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.Nullable{System.Int32},System.String,System.Threading.CancellationToken)">
            <summary>
            This operation generates a description of an image in human readable
            language with complete sentences. The description is based on a collection
            of content tags, which are also returned by the operation. More than one
            description can be generated for each image. Descriptions are ordered by
            their confidence score. All descriptions are in English.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='maxCandidates'>
            Maximum number of candidate descriptions to be returned.  The default is 1.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.DetectObjectsAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.Threading.CancellationToken)">
            <summary>
            Performs object detection on the specified image.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.ListModelsAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.Threading.CancellationToken)">
            <summary>
            This operation returns the list of domain-specific models that are
            supported by the Computer Vision API. Currently, the API supports following
            domain-specific models: celebrity recognizer, landmark recognizer.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.AnalyzeImageByDomainAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.String,System.String,System.Threading.CancellationToken)">
            <summary>
            This operation recognizes content within an image by applying a
            domain-specific model. The list of domain-specific models that are
            supported by the Computer Vision API can be retrieved using the /models GET
            request. Currently, the API provides following domain-specific models:
            celebrities, landmarks.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON.
            If the request failed, the response will contain an error code and a
            message to help understand what went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='model'>
            The domain-specific content to recognize.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.RecognizePrintedTextAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.Boolean,System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLanguages,System.Threading.CancellationToken)">
            <summary>
            Optical Character Recognition (OCR) detects text in an image and extracts
            the recognized characters into a machine-usable character stream.
            Upon success, the OCR results will be returned.
            Upon failure, the error code together with an error message will be
            returned. The error code can be one of InvalidImageUrl, InvalidImageFormat,
            InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or
            InternalServerError.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='detectOrientation'>
            Whether detect the text orientation in the image. With
            detectOrientation=true the OCR service tries to detect the image
            orientation and correct it before further processing (e.g. if it's
            upside-down).
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The BCP-47 language code of the text to be detected in the image. The
            default value is 'unk'. Possible values include: 'unk', 'zh-Hans',
            'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it',
            'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro',
            'sr-Cyrl', 'sr-Latn', 'sk'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.TagImageAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.String,System.Threading.CancellationToken)">
            <summary>
            This operation generates a list of words, or tags, that are relevant to the
            content of the supplied image. The Computer Vision API can return tags
            based on objects, living beings, scenery or actions found in images. Unlike
            categories, tags are not organized according to a hierarchical
            classification system, but correspond to image content. Tags may contain
            hints to avoid ambiguity or provide context, for example the tag "cello"
            may be accompanied by the hint "musical instrument". All tags are in
            English.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.GenerateThumbnailAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.Int32,System.Int32,System.String,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
            <summary>
            This operation generates a thumbnail image with the user-specified width
            and height. By default, the service analyzes the image, identifies the
            region of interest (ROI), and generates smart cropping coordinates based on
            the ROI. Smart cropping helps when you specify an aspect ratio that differs
            from that of the input image.
            A successful response contains the thumbnail image binary. If the request
            failed, the response contains an error code and a message to help determine
            what went wrong.
            Upon failure, the error code and an error message are returned. The error
            code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
            InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or
            InternalServerError.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='width'>
            Width of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='height'>
            Height of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='smartCropping'>
            Boolean flag for enabling smart cropping.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.GetAreaOfInterestAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.Threading.CancellationToken)">
            <summary>
            This operation returns a bounding box around the most important area of the
            image.
            A successful response will be returned in JSON. If the request failed, the
            response contains an error code and a message to help determine what went
            wrong.
            Upon failure, the error code and an error message are returned. The error
            code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
            NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.RecognizeTextAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Threading.CancellationToken)">
            <summary>
            Recognize Text operation. When you use the Recognize Text interface, the
            response contains a field called 'Operation-Location'. The
            'Operation-Location' field contains the URL that you must use for your Get
            Recognize Text Operation Result operation.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.GetTextOperationResultAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.Threading.CancellationToken)">
            <summary>
            This interface is used for getting text operation result. The URL to this
            interface should be retrieved from 'Operation-Location' field returned from
            Recognize Text interface.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='operationId'>
            Id of the text operation returned in the response of the 'Recognize Text'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.BatchReadFileAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Threading.CancellationToken)">
            <summary>
            Use this interface to get the result of a Read operation, employing the
            state-of-the-art Optical Character Recognition (OCR) algorithms optimized
            for text-heavy documents. When you use the Read File interface, the
            response contains a field called "Operation-Location". The
            "Operation-Location" field contains the URL that you must use for your
            "Read Operation Result" operation to access OCR results.â€‹
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.GetReadOperationResultAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.Threading.CancellationToken)">
            <summary>
            This interface is used for getting OCR results of Read operation. The URL
            to this interface should be retrieved from "Operation-Location" field
            returned from Batch Read File interface.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='operationId'>
            Id of read operation returned in the response of the "Batch Read File"
            interface.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.AnalyzeImageInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.IO.Stream,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Details},System.String,System.Threading.CancellationToken)">
            <summary>
            This operation extracts a rich set of visual features based on the image
            content.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL. Within your request, there is an optional parameter to allow
            you to choose which features to return. By default, image categories are
            returned in the response.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='visualFeatures'>
            A string indicating what visual feature types to return. Multiple values
            should be comma-separated. Valid visual feature types include: Categories -
            categorizes image content according to a taxonomy defined in documentation.
            Tags - tags the image with a detailed list of words related to the image
            content. Description - describes the image content with a complete English
            sentence. Faces - detects if faces are present. If present, generate
            coordinates, gender and age. ImageType - detects if image is clipart or a
            line drawing. Color - determines the accent color, dominant color, and
            whether an image is black&amp;white. Adult - detects if the image is
            pornographic in nature (depicts nudity or a sex act).  Sexually suggestive
            content is also detected. Objects - detects various objects within an
            image, including the approximate location. The Objects argument is only
            available in English. Brands - detects various brands within an image,
            including the approximate location. The Brands argument is only available
            in English.
            </param>
            <param name='details'>
            A string indicating which domain-specific details to return. Multiple
            values should be comma-separated. Valid visual feature types include:
            Celebrities - identifies celebrities if detected in the image, Landmarks -
            identifies notable landmarks in the image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.GetAreaOfInterestInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.IO.Stream,System.Threading.CancellationToken)">
            <summary>
            This operation returns a bounding box around the most important area of the
            image.
            A successful response will be returned in JSON. If the request failed, the
            response contains an error code and a message to help determine what went
            wrong.
            Upon failure, the error code and an error message are returned. The error
            code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
            NotSupportedImage, FailedToProcess, Timeout, or InternalServerError.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.DescribeImageInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.IO.Stream,System.Nullable{System.Int32},System.String,System.Threading.CancellationToken)">
            <summary>
            This operation generates a description of an image in human readable
            language with complete sentences. The description is based on a collection
            of content tags, which are also returned by the operation. More than one
            description can be generated for each image. Descriptions are ordered by
            their confidence score. All descriptions are in English.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='maxCandidates'>
            Maximum number of candidate descriptions to be returned.  The default is 1.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.DetectObjectsInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.IO.Stream,System.Threading.CancellationToken)">
            <summary>
            Performs object detection on the specified image.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.GenerateThumbnailInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.Int32,System.Int32,System.IO.Stream,System.Nullable{System.Boolean},System.Threading.CancellationToken)">
            <summary>
            This operation generates a thumbnail image with the user-specified width
            and height. By default, the service analyzes the image, identifies the
            region of interest (ROI), and generates smart cropping coordinates based on
            the ROI. Smart cropping helps when you specify an aspect ratio that differs
            from that of the input image.
            A successful response contains the thumbnail image binary. If the request
            failed, the response contains an error code and a message to help determine
            what went wrong.
            Upon failure, the error code and an error message are returned. The error
            code could be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize,
            InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout, or
            InternalServerError.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='width'>
            Width of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='height'>
            Height of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='smartCropping'>
            Boolean flag for enabling smart cropping.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.AnalyzeImageByDomainInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.String,System.IO.Stream,System.String,System.Threading.CancellationToken)">
            <summary>
            This operation recognizes content within an image by applying a
            domain-specific model. The list of domain-specific models that are
            supported by the Computer Vision API can be retrieved using the /models GET
            request. Currently, the API provides following domain-specific models:
            celebrities, landmarks.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON.
            If the request failed, the response will contain an error code and a
            message to help understand what went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='model'>
            The domain-specific content to recognize.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.RecognizePrintedTextInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.Boolean,System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLanguages,System.Threading.CancellationToken)">
            <summary>
            Optical Character Recognition (OCR) detects text in an image and extracts
            the recognized characters into a machine-usable character stream.
            Upon success, the OCR results will be returned.
            Upon failure, the error code together with an error message will be
            returned. The error code can be one of InvalidImageUrl, InvalidImageFormat,
            InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or
            InternalServerError.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='detectOrientation'>
            Whether detect the text orientation in the image. With
            detectOrientation=true the OCR service tries to detect the image
            orientation and correct it before further processing (e.g. if it's
            upside-down).
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The BCP-47 language code of the text to be detected in the image. The
            default value is 'unk'. Possible values include: 'unk', 'zh-Hans',
            'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it',
            'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro',
            'sr-Cyrl', 'sr-Latn', 'sk'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.TagImageInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.IO.Stream,System.String,System.Threading.CancellationToken)">
            <summary>
            This operation generates a list of words, or tags, that are relevant to the
            content of the supplied image. The Computer Vision API can return tags
            based on objects, living beings, scenery or actions found in images. Unlike
            categories, tags are not organized according to a hierarchical
            classification system, but correspond to image content. Tags may contain
            hints to avoid ambiguity or provide context, for example the tag "cello"
            may be accompanied by the hint "musical instrument". All tags are in
            English.
            Two input methods are supported -- (1) Uploading an image or (2) specifying
            an image URL.
            A successful response will be returned in JSON. If the request failed, the
            response will contain an error code and a message to help understand what
            went wrong.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is not
            specified, the default value is &amp;quot;en&amp;quot;.Supported
            languages:en - English, Default. es - Spanish, ja - Japanese, pt -
            Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es',
            'ja', 'pt', 'zh'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.RecognizeTextInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Threading.CancellationToken)">
            <summary>
            Recognize Text operation. When you use the Recognize Text interface, the
            response contains a field called 'Operation-Location'. The
            'Operation-Location' field contains the URL that you must use for your Get
            Recognize Text Operation Result operation.
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.ComputerVisionClientExtensions.BatchReadFileInStreamAsync(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient,System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Threading.CancellationToken)">
            <summary>
            Use this interface to get the result of a Read Document operation,
            employing the state-of-the-art Optical Character Recognition (OCR)
            algorithms optimized for text-heavy documents. When you use the Read
            Document interface, the response contains a field called
            "Operation-Location". The "Operation-Location" field contains the URL that
            you must use for your "Get Read Result operation" to access OCR results.â€‹
            </summary>
            <param name='operations'>
            The operations group for this extension method.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient">
            <summary>
            The Computer Vision API provides state-of-the-art algorithms to process
            images and return information. For example, it can be used to determine
            if an image contains mature content, or it can be used to find all the
            faces in an image.  It also has other features like estimating dominant
            and accent colors, categorizing the content of images, and describing
            an image with complete English sentences.  Additionally, it can also
            intelligently generate images thumbnails for displaying large images
            effectively.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.SerializationSettings">
            <summary>
            The base URI of the service.
            </summary>
            <summary>
            Gets or sets json serialization settings.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.DeserializationSettings">
            <summary>
            Gets or sets json deserialization settings.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.Endpoint">
            <summary>
            Supported Cognitive Services endpoints.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.Credentials">
            <summary>
            Subscription credentials which uniquely identify client
            subscription.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.AnalyzeImageWithHttpMessagesAsync(System.String,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Details},System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation extracts a rich set of visual features based on the
            image content.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL. Within your request, there is an optional
            parameter to allow you to choose which features to return. By
            default, image categories are returned in the response.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='visualFeatures'>
            A string indicating what visual feature types to return. Multiple
            values should be comma-separated. Valid visual feature types
            include: Categories - categorizes image content according to a
            taxonomy defined in documentation. Tags - tags the image with a
            detailed list of words related to the image content. Description -
            describes the image content with a complete English sentence. Faces
            - detects if faces are present. If present, generate coordinates,
            gender and age. ImageType - detects if image is clipart or a line
            drawing. Color - determines the accent color, dominant color, and
            whether an image is black&amp;white. Adult - detects if the image
            is pornographic in nature (depicts nudity or a sex act).  Sexually
            suggestive content is also detected. Objects - detects various
            objects within an image, including the approximate location. The
            Objects argument is only available in English. Brands - detects
            various brands within an image, including the approximate location.
            The Brands argument is only available in English.
            </param>
            <param name='details'>
            A string indicating which domain-specific details to return.
            Multiple values should be comma-separated. Valid visual feature
            types include: Celebrities - identifies celebrities if detected in
            the image, Landmarks - identifies notable landmarks in the image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is
            not specified, the default value is
            &amp;quot;en&amp;quot;.Supported languages:en - English, Default.
            es - Spanish, ja - Japanese, pt - Portuguese, zh - Simplified
            Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.DescribeImageWithHttpMessagesAsync(System.String,System.Nullable{System.Int32},System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a description of an image in human
            readable language with complete sentences. The description is based
            on a collection of content tags, which are also returned by the
            operation. More than one description can be generated for each
            image. Descriptions are ordered by their confidence score. All
            descriptions are in English.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='maxCandidates'>
            Maximum number of candidate descriptions to be returned.  The
            default is 1.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is
            not specified, the default value is
            &amp;quot;en&amp;quot;.Supported languages:en - English, Default.
            es - Spanish, ja - Japanese, pt - Portuguese, zh - Simplified
            Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.DetectObjectsWithHttpMessagesAsync(System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Performs object detection on the specified image.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.ListModelsWithHttpMessagesAsync(System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation returns the list of domain-specific models that are
            supported by the Computer Vision API. Currently, the API supports
            following domain-specific models: celebrity recognizer, landmark
            recognizer.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.AnalyzeImageByDomainWithHttpMessagesAsync(System.String,System.String,System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation recognizes content within an image by applying a
            domain-specific model. The list of domain-specific models that are
            supported by the Computer Vision API can be retrieved using the
            /models GET request. Currently, the API provides following
            domain-specific models: celebrities, landmarks.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL.
            A successful response will be returned in JSON.
            If the request failed, the response will contain an error code and
            a message to help understand what went wrong.
            </summary>
            <param name='model'>
            The domain-specific content to recognize.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is
            not specified, the default value is
            &amp;quot;en&amp;quot;.Supported languages:en - English, Default.
            es - Spanish, ja - Japanese, pt - Portuguese, zh - Simplified
            Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.RecognizePrintedTextWithHttpMessagesAsync(System.Boolean,System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLanguages,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Optical Character Recognition (OCR) detects text in an image and
            extracts the recognized characters into a machine-usable character
            stream.
            Upon success, the OCR results will be returned.
            Upon failure, the error code together with an error message will be
            returned. The error code can be one of InvalidImageUrl,
            InvalidImageFormat, InvalidImageSize, NotSupportedImage,
            NotSupportedLanguage, or InternalServerError.
            </summary>
            <param name='detectOrientation'>
            Whether detect the text orientation in the image. With
            detectOrientation=true the OCR service tries to detect the image
            orientation and correct it before further processing (e.g. if it's
            upside-down).
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The BCP-47 language code of the text to be detected in the image.
            The default value is 'unk'. Possible values include: 'unk',
            'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de',
            'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv',
            'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.TagImageWithHttpMessagesAsync(System.String,System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a list of words, or tags, that are
            relevant to the content of the supplied image. The Computer Vision
            API can return tags based on objects, living beings, scenery or
            actions found in images. Unlike categories, tags are not organized
            according to a hierarchical classification system, but correspond
            to image content. Tags may contain hints to avoid ambiguity or
            provide context, for example the tag "cello" may be accompanied by
            the hint "musical instrument". All tags are in English.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is
            not specified, the default value is
            &amp;quot;en&amp;quot;.Supported languages:en - English, Default.
            es - Spanish, ja - Japanese, pt - Portuguese, zh - Simplified
            Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.GenerateThumbnailWithHttpMessagesAsync(System.Int32,System.Int32,System.String,System.Nullable{System.Boolean},System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a thumbnail image with the user-specified
            width and height. By default, the service analyzes the image,
            identifies the region of interest (ROI), and generates smart
            cropping coordinates based on the ROI. Smart cropping helps when
            you specify an aspect ratio that differs from that of the input
            image.
            A successful response contains the thumbnail image binary. If the
            request failed, the response contains an error code and a message
            to help determine what went wrong.
            Upon failure, the error code and an error message are returned. The
            error code could be one of InvalidImageUrl, InvalidImageFormat,
            InvalidImageSize, InvalidThumbnailSize, NotSupportedImage,
            FailedToProcess, Timeout, or InternalServerError.
            </summary>
            <param name='width'>
            Width of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='height'>
            Height of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='smartCropping'>
            Boolean flag for enabling smart cropping.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.GetAreaOfInterestWithHttpMessagesAsync(System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation returns a bounding box around the most important
            area of the image.
            A successful response will be returned in JSON. If the request
            failed, the response contains an error code and a message to help
            determine what went wrong.
            Upon failure, the error code and an error message are returned. The
            error code could be one of InvalidImageUrl, InvalidImageFormat,
            InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
            InternalServerError.
            </summary>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.RecognizeTextWithHttpMessagesAsync(System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Recognize Text operation. When you use the Recognize Text
            interface, the response contains a field called
            'Operation-Location'. The 'Operation-Location' field contains the
            URL that you must use for your Get Recognize Text Operation Result
            operation.
            </summary>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.GetTextOperationResultWithHttpMessagesAsync(System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This interface is used for getting text operation result. The URL
            to this interface should be retrieved from 'Operation-Location'
            field returned from Recognize Text interface.
            </summary>
            <param name='operationId'>
            Id of the text operation returned in the response of the 'Recognize
            Text'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.BatchReadFileWithHttpMessagesAsync(System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Use this interface to get the result of a Read operation, employing
            the state-of-the-art Optical Character Recognition (OCR) algorithms
            optimized for text-heavy documents. When you use the Read File
            interface, the response contains a field called
            "Operation-Location". The "Operation-Location" field contains the
            URL that you must use for your "Read Operation Result" operation to
            access OCR results.â€‹
            </summary>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='url'>
            Publicly reachable URL of an image.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.GetReadOperationResultWithHttpMessagesAsync(System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This interface is used for getting OCR results of Read operation.
            The URL to this interface should be retrieved from
            "Operation-Location" field returned from Batch Read File interface.
            </summary>
            <param name='operationId'>
            Id of read operation returned in the response of the "Batch Read
            File" interface.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.AnalyzeImageInStreamWithHttpMessagesAsync(System.IO.Stream,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Details},System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation extracts a rich set of visual features based on the
            image content.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL. Within your request, there is an optional
            parameter to allow you to choose which features to return. By
            default, image categories are returned in the response.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='visualFeatures'>
            A string indicating what visual feature types to return. Multiple
            values should be comma-separated. Valid visual feature types
            include: Categories - categorizes image content according to a
            taxonomy defined in documentation. Tags - tags the image with a
            detailed list of words related to the image content. Description -
            describes the image content with a complete English sentence. Faces
            - detects if faces are present. If present, generate coordinates,
            gender and age. ImageType - detects if image is clipart or a line
            drawing. Color - determines the accent color, dominant color, and
            whether an image is black&amp;white. Adult - detects if the image
            is pornographic in nature (depicts nudity or a sex act).  Sexually
            suggestive content is also detected. Objects - detects various
            objects within an image, including the approximate location. The
            Objects argument is only available in English. Brands - detects
            various brands within an image, including the approximate location.
            The Brands argument is only available in English.
            </param>
            <param name='details'>
            A string indicating which domain-specific details to return.
            Multiple values should be comma-separated. Valid visual feature
            types include: Celebrities - identifies celebrities if detected in
            the image, Landmarks - identifies notable landmarks in the image.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is
            not specified, the default value is
            &amp;quot;en&amp;quot;.Supported languages:en - English, Default.
            es - Spanish, ja - Japanese, pt - Portuguese, zh - Simplified
            Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.GetAreaOfInterestInStreamWithHttpMessagesAsync(System.IO.Stream,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation returns a bounding box around the most important
            area of the image.
            A successful response will be returned in JSON. If the request
            failed, the response contains an error code and a message to help
            determine what went wrong.
            Upon failure, the error code and an error message are returned. The
            error code could be one of InvalidImageUrl, InvalidImageFormat,
            InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or
            InternalServerError.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.DescribeImageInStreamWithHttpMessagesAsync(System.IO.Stream,System.Nullable{System.Int32},System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a description of an image in human
            readable language with complete sentences. The description is based
            on a collection of content tags, which are also returned by the
            operation. More than one description can be generated for each
            image. Descriptions are ordered by their confidence score. All
            descriptions are in English.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='maxCandidates'>
            Maximum number of candidate descriptions to be returned.  The
            default is 1.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is
            not specified, the default value is
            &amp;quot;en&amp;quot;.Supported languages:en - English, Default.
            es - Spanish, ja - Japanese, pt - Portuguese, zh - Simplified
            Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.DetectObjectsInStreamWithHttpMessagesAsync(System.IO.Stream,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Performs object detection on the specified image.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.GenerateThumbnailInStreamWithHttpMessagesAsync(System.Int32,System.Int32,System.IO.Stream,System.Nullable{System.Boolean},System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a thumbnail image with the user-specified
            width and height. By default, the service analyzes the image,
            identifies the region of interest (ROI), and generates smart
            cropping coordinates based on the ROI. Smart cropping helps when
            you specify an aspect ratio that differs from that of the input
            image.
            A successful response contains the thumbnail image binary. If the
            request failed, the response contains an error code and a message
            to help determine what went wrong.
            Upon failure, the error code and an error message are returned. The
            error code could be one of InvalidImageUrl, InvalidImageFormat,
            InvalidImageSize, InvalidThumbnailSize, NotSupportedImage,
            FailedToProcess, Timeout, or InternalServerError.
            </summary>
            <param name='width'>
            Width of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='height'>
            Height of the thumbnail, in pixels. It must be between 1 and 1024.
            Recommended minimum of 50.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='smartCropping'>
            Boolean flag for enabling smart cropping.
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.AnalyzeImageByDomainInStreamWithHttpMessagesAsync(System.String,System.IO.Stream,System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation recognizes content within an image by applying a
            domain-specific model. The list of domain-specific models that are
            supported by the Computer Vision API can be retrieved using the
            /models GET request. Currently, the API provides following
            domain-specific models: celebrities, landmarks.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL.
            A successful response will be returned in JSON.
            If the request failed, the response will contain an error code and
            a message to help understand what went wrong.
            </summary>
            <param name='model'>
            The domain-specific content to recognize.
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is
            not specified, the default value is
            &amp;quot;en&amp;quot;.Supported languages:en - English, Default.
            es - Spanish, ja - Japanese, pt - Portuguese, zh - Simplified
            Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.RecognizePrintedTextInStreamWithHttpMessagesAsync(System.Boolean,System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLanguages,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Optical Character Recognition (OCR) detects text in an image and
            extracts the recognized characters into a machine-usable character
            stream.
            Upon success, the OCR results will be returned.
            Upon failure, the error code together with an error message will be
            returned. The error code can be one of InvalidImageUrl,
            InvalidImageFormat, InvalidImageSize, NotSupportedImage,
            NotSupportedLanguage, or InternalServerError.
            </summary>
            <param name='detectOrientation'>
            Whether detect the text orientation in the image. With
            detectOrientation=true the OCR service tries to detect the image
            orientation and correct it before further processing (e.g. if it's
            upside-down).
            </param>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The BCP-47 language code of the text to be detected in the image.
            The default value is 'unk'. Possible values include: 'unk',
            'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de',
            'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv',
            'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.TagImageInStreamWithHttpMessagesAsync(System.IO.Stream,System.String,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            This operation generates a list of words, or tags, that are
            relevant to the content of the supplied image. The Computer Vision
            API can return tags based on objects, living beings, scenery or
            actions found in images. Unlike categories, tags are not organized
            according to a hierarchical classification system, but correspond
            to image content. Tags may contain hints to avoid ambiguity or
            provide context, for example the tag "cello" may be accompanied by
            the hint "musical instrument". All tags are in English.
            Two input methods are supported -- (1) Uploading an image or (2)
            specifying an image URL.
            A successful response will be returned in JSON. If the request
            failed, the response will contain an error code and a message to
            help understand what went wrong.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='language'>
            The desired language for output generation. If this parameter is
            not specified, the default value is
            &amp;quot;en&amp;quot;.Supported languages:en - English, Default.
            es - Spanish, ja - Japanese, pt - Portuguese, zh - Simplified
            Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.RecognizeTextInStreamWithHttpMessagesAsync(System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Recognize Text operation. When you use the Recognize Text
            interface, the response contains a field called
            'Operation-Location'. The 'Operation-Location' field contains the
            URL that you must use for your Get Recognize Text Operation Result
            operation.
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.IComputerVisionClient.BatchReadFileInStreamWithHttpMessagesAsync(System.IO.Stream,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode,System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.String}},System.Threading.CancellationToken)">
            <summary>
            Use this interface to get the result of a Read Document operation,
            employing the state-of-the-art Optical Character Recognition (OCR)
            algorithms optimized for text-heavy documents. When you use the
            Read Document interface, the response contains a field called
            "Operation-Location". The "Operation-Location" field contains the
            URL that you must use for your "Get Read Result operation" to
            access OCR results.â€‹
            </summary>
            <param name='image'>
            An image stream.
            </param>
            <param name='mode'>
            Type of text to recognize. Possible values include: 'Handwritten',
            'Printed'
            </param>
            <param name='customHeaders'>
            The headers that will be added to request.
            </param>
            <param name='cancellationToken'>
            The cancellation token.
            </param>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AdultInfo">
            <summary>
            An object describing whether the image contains adult-oriented content
            and/or is racy.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AdultInfo.#ctor">
            <summary>
            Initializes a new instance of the AdultInfo class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AdultInfo.#ctor(System.Boolean,System.Boolean,System.Double,System.Double)">
            <summary>
            Initializes a new instance of the AdultInfo class.
            </summary>
            <param name="isAdultContent">A value indicating if the image
            contains adult-oriented content.</param>
            <param name="isRacyContent">A value indicating if the image is
            racy.</param>
            <param name="adultScore">Score from 0 to 1 that indicates how much
            the content is considered adult-oriented within the image.</param>
            <param name="racyScore">Score from 0 to 1 that indicates how
            suggestive is the image.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AdultInfo.IsAdultContent">
            <summary>
            Gets or sets a value indicating if the image contains
            adult-oriented content.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AdultInfo.IsRacyContent">
            <summary>
            Gets or sets a value indicating if the image is racy.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AdultInfo.AdultScore">
            <summary>
            Gets or sets score from 0 to 1 that indicates how much the content
            is considered adult-oriented within the image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AdultInfo.RacyScore">
            <summary>
            Gets or sets score from 0 to 1 that indicates how suggestive is the
            image.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AreaOfInterestResult">
            <summary>
            Result of AreaOfInterest operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AreaOfInterestResult.#ctor">
            <summary>
            Initializes a new instance of the AreaOfInterestResult class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AreaOfInterestResult.#ctor(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect,System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata)">
            <summary>
            Initializes a new instance of the AreaOfInterestResult class.
            </summary>
            <param name="areaOfInterest">A bounding box for an area of interest
            inside an image.</param>
            <param name="requestId">Id of the REST API request.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AreaOfInterestResult.AreaOfInterest">
            <summary>
            Gets a bounding box for an area of interest inside an image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AreaOfInterestResult.RequestId">
            <summary>
            Gets or sets id of the REST API request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AreaOfInterestResult.Metadata">
            <summary>
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BatchReadFileHeaders">
            <summary>
            Defines headers for BatchReadFile operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BatchReadFileHeaders.#ctor">
            <summary>
            Initializes a new instance of the BatchReadFileHeaders class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BatchReadFileHeaders.#ctor(System.String)">
            <summary>
            Initializes a new instance of the BatchReadFileHeaders class.
            </summary>
            <param name="operationLocation">URL to query for status of the
            operation. The operation ID will expire in 48 hours. </param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BatchReadFileHeaders.OperationLocation">
            <summary>
            Gets or sets URL to query for status of the operation. The
            operation ID will expire in 48 hours.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BatchReadFileInStreamHeaders">
            <summary>
            Defines headers for BatchReadFileInStream operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BatchReadFileInStreamHeaders.#ctor">
            <summary>
            Initializes a new instance of the BatchReadFileInStreamHeaders
            class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BatchReadFileInStreamHeaders.#ctor(System.String)">
            <summary>
            Initializes a new instance of the BatchReadFileInStreamHeaders
            class.
            </summary>
            <param name="operationLocation">URL to query for status of the
            operation. The operation ID will expire in 48 hours. </param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BatchReadFileInStreamHeaders.OperationLocation">
            <summary>
            Gets or sets URL to query for status of the operation. The
            operation ID will expire in 48 hours.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect">
            <summary>
            A bounding box for an area inside an image.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect.#ctor">
            <summary>
            Initializes a new instance of the BoundingRect class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect.#ctor(System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the BoundingRect class.
            </summary>
            <param name="x">X-coordinate of the top left point of the area, in
            pixels.</param>
            <param name="y">Y-coordinate of the top left point of the area, in
            pixels.</param>
            <param name="w">Width measured from the top-left point of the area,
            in pixels.</param>
            <param name="h">Height measured from the top-left point of the
            area, in pixels.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect.X">
            <summary>
            Gets or sets x-coordinate of the top left point of the area, in
            pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect.Y">
            <summary>
            Gets or sets y-coordinate of the top left point of the area, in
            pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect.W">
            <summary>
            Gets or sets width measured from the top-left point of the area, in
            pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect.H">
            <summary>
            Gets or sets height measured from the top-left point of the area,
            in pixels.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Category">
            <summary>
            An object describing identified category.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Category.#ctor">
            <summary>
            Initializes a new instance of the Category class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Category.#ctor(System.String,System.Double,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CategoryDetail)">
            <summary>
            Initializes a new instance of the Category class.
            </summary>
            <param name="name">Name of the category.</param>
            <param name="score">Scoring of the category.</param>
            <param name="detail">Details of the identified category.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Category.Name">
            <summary>
            Gets or sets name of the category.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Category.Score">
            <summary>
            Gets or sets scoring of the category.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Category.Detail">
            <summary>
            Gets or sets details of the identified category.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CategoryDetail">
            <summary>
            An object describing additional category details.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CategoryDetail.#ctor">
            <summary>
            Initializes a new instance of the CategoryDetail class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CategoryDetail.#ctor(System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebritiesModel},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarksModel})">
            <summary>
            Initializes a new instance of the CategoryDetail class.
            </summary>
            <param name="celebrities">An array of celebrities if any
            identified.</param>
            <param name="landmarks">An array of landmarks if any
            identified.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CategoryDetail.Celebrities">
            <summary>
            Gets or sets an array of celebrities if any identified.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CategoryDetail.Landmarks">
            <summary>
            Gets or sets an array of landmarks if any identified.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebritiesModel">
            <summary>
            An object describing possible celebrity identification.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebritiesModel.#ctor">
            <summary>
            Initializes a new instance of the CelebritiesModel class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebritiesModel.#ctor(System.String,System.Double,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle)">
            <summary>
            Initializes a new instance of the CelebritiesModel class.
            </summary>
            <param name="name">Name of the celebrity.</param>
            <param name="confidence">Confidence level for the celebrity
            recognition as a value ranging from 0 to 1.</param>
            <param name="faceRectangle">Location of the identified face in the
            image.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebritiesModel.Name">
            <summary>
            Gets or sets name of the celebrity.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebritiesModel.Confidence">
            <summary>
            Gets or sets confidence level for the celebrity recognition as a
            value ranging from 0 to 1.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebritiesModel.FaceRectangle">
            <summary>
            Gets or sets location of the identified face in the image.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebrityResults">
            <summary>
            Result of domain-specific classifications for the domain of
            celebrities.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebrityResults.#ctor">
            <summary>
            Initializes a new instance of the CelebrityResults class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebrityResults.#ctor(System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebritiesModel},System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata)">
            <summary>
            Initializes a new instance of the CelebrityResults class.
            </summary>
            <param name="celebrities">List of celebrities recognized in the
            image.</param>
            <param name="requestId">Id of the REST API request.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebrityResults.Celebrities">
            <summary>
            Gets or sets list of celebrities recognized in the image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebrityResults.RequestId">
            <summary>
            Gets or sets id of the REST API request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.CelebrityResults.Metadata">
            <summary>
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo">
            <summary>
            An object providing additional metadata describing color attributes.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo.#ctor">
            <summary>
            Initializes a new instance of the ColorInfo class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo.#ctor(System.String,System.String,System.Collections.Generic.IList{System.String},System.String,System.Boolean)">
            <summary>
            Initializes a new instance of the ColorInfo class.
            </summary>
            <param name="dominantColorForeground">Possible dominant foreground
            color.</param>
            <param name="dominantColorBackground">Possible dominant background
            color.</param>
            <param name="dominantColors">An array of possible dominant
            colors.</param>
            <param name="accentColor">Possible accent color.</param>
            <param name="isBWImg">A value indicating if the image is black and
            white.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo.DominantColorForeground">
            <summary>
            Gets or sets possible dominant foreground color.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo.DominantColorBackground">
            <summary>
            Gets or sets possible dominant background color.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo.DominantColors">
            <summary>
            Gets or sets an array of possible dominant colors.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo.AccentColor">
            <summary>
            Gets or sets possible accent color.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo.IsBWImg">
            <summary>
            Gets or sets a value indicating if the image is black and white.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionError">
            <summary>
            Details about the API request error.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionError.#ctor">
            <summary>
            Initializes a new instance of the ComputerVisionError class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionError.#ctor(System.Object,System.String,System.String)">
            <summary>
            Initializes a new instance of the ComputerVisionError class.
            </summary>
            <param name="code">The error code.</param>
            <param name="message">A message explaining the error reported by
            the service.</param>
            <param name="requestId">A unique request identifier.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionError.Code">
            <summary>
            Gets or sets the error code.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionError.Message">
            <summary>
            Gets or sets a message explaining the error reported by the
            service.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionError.RequestId">
            <summary>
            Gets or sets a unique request identifier.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionError.Validate">
            <summary>
            Validate the object.
            </summary>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown if validation fails
            </exception>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException">
            <summary>
            Exception thrown for an invalid response with ComputerVisionError
            information.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException.Request">
            <summary>
            Gets information about the associated HTTP request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException.Response">
            <summary>
            Gets information about the associated HTTP response.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException.Body">
            <summary>
            Gets or sets the body object.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException.#ctor">
            <summary>
            Initializes a new instance of the ComputerVisionErrorException class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException.#ctor(System.String)">
            <summary>
            Initializes a new instance of the ComputerVisionErrorException class.
            </summary>
            <param name="message">The exception message.</param>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ComputerVisionErrorException.#ctor(System.String,System.Exception)">
            <summary>
            Initializes a new instance of the ComputerVisionErrorException class.
            </summary>
            <param name="message">The exception message.</param>
            <param name="innerException">Inner exception.</param>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Details">
            <summary>
            Defines values for Details.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedBrand">
            <summary>
            A brand detected in an image.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedBrand.#ctor">
            <summary>
            Initializes a new instance of the DetectedBrand class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedBrand.#ctor(System.String,System.Double,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect)">
            <summary>
            Initializes a new instance of the DetectedBrand class.
            </summary>
            <param name="name">Label for the brand.</param>
            <param name="confidence">Confidence score of having observed the
            brand in the image, as a value ranging from 0 to 1.</param>
            <param name="rectangle">Approximate location of the detected
            brand.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedBrand.Name">
            <summary>
            Gets label for the brand.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedBrand.Confidence">
            <summary>
            Gets confidence score of having observed the brand in the image, as
            a value ranging from 0 to 1.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedBrand.Rectangle">
            <summary>
            Gets approximate location of the detected brand.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject">
            <summary>
            An object detected in an image.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject.#ctor">
            <summary>
            Initializes a new instance of the DetectedObject class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject.#ctor(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.BoundingRect,System.String,System.Double,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ObjectHierarchy)">
            <summary>
            Initializes a new instance of the DetectedObject class.
            </summary>
            <param name="rectangle">Approximate location of the detected
            object.</param>
            <param name="objectProperty">Label for the object.</param>
            <param name="confidence">Confidence score of having observed the
            object in the image, as a value ranging from 0 to 1.</param>
            <param name="parent">The parent object, from a taxonomy
            perspective.
            The parent object is a more generic form of this object.  For
            example, a 'bulldog' would have a parent of 'dog'.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject.Rectangle">
            <summary>
            Gets approximate location of the detected object.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject.ObjectProperty">
            <summary>
            Gets or sets label for the object.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject.Confidence">
            <summary>
            Gets or sets confidence score of having observed the object in the
            image, as a value ranging from 0 to 1.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject.Parent">
            <summary>
            Gets or sets the parent object, from a taxonomy perspective.
            The parent object is a more generic form of this object.  For
            example, a 'bulldog' would have a parent of 'dog'.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectResult">
            <summary>
            Result of a DetectImage call.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectResult.#ctor">
            <summary>
            Initializes a new instance of the DetectResult class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectResult.#ctor(System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject},System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata)">
            <summary>
            Initializes a new instance of the DetectResult class.
            </summary>
            <param name="objects">An array of detected objects.</param>
            <param name="requestId">Id of the REST API request.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectResult.Objects">
            <summary>
            Gets an array of detected objects.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectResult.RequestId">
            <summary>
            Gets or sets id of the REST API request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectResult.Metadata">
            <summary>
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DomainModelResults">
            <summary>
            Result of image analysis using a specific domain model including
            additional metadata.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DomainModelResults.#ctor">
            <summary>
            Initializes a new instance of the DomainModelResults class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DomainModelResults.#ctor(System.Object,System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata)">
            <summary>
            Initializes a new instance of the DomainModelResults class.
            </summary>
            <param name="result">Model-specific response.</param>
            <param name="requestId">Id of the REST API request.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DomainModelResults.Result">
            <summary>
            Gets or sets model-specific response.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DomainModelResults.RequestId">
            <summary>
            Gets or sets id of the REST API request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DomainModelResults.Metadata">
            <summary>
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceDescription">
            <summary>
            An object describing a face identified in the image.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceDescription.#ctor">
            <summary>
            Initializes a new instance of the FaceDescription class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceDescription.#ctor(System.Int32,System.Nullable{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Gender},Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle)">
            <summary>
            Initializes a new instance of the FaceDescription class.
            </summary>
            <param name="age">Possible age of the face.</param>
            <param name="gender">Possible gender of the face. Possible values
            include: 'Male', 'Female'</param>
            <param name="faceRectangle">Rectangle in the image containing the
            identified face.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceDescription.Age">
            <summary>
            Gets or sets possible age of the face.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceDescription.Gender">
            <summary>
            Gets or sets possible gender of the face. Possible values include:
            'Male', 'Female'
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceDescription.FaceRectangle">
            <summary>
            Gets or sets rectangle in the image containing the identified face.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle">
            <summary>
            An object describing face rectangle.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle.#ctor">
            <summary>
            Initializes a new instance of the FaceRectangle class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle.#ctor(System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the FaceRectangle class.
            </summary>
            <param name="left">X-coordinate of the top left point of the face,
            in pixels.</param>
            <param name="top">Y-coordinate of the top left point of the face,
            in pixels.</param>
            <param name="width">Width measured from the top-left point of the
            face, in pixels.</param>
            <param name="height">Height measured from the top-left point of the
            face, in pixels.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle.Left">
            <summary>
            Gets or sets x-coordinate of the top left point of the face, in
            pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle.Top">
            <summary>
            Gets or sets y-coordinate of the top left point of the face, in
            pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle.Width">
            <summary>
            Gets or sets width measured from the top-left point of the face, in
            pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceRectangle.Height">
            <summary>
            Gets or sets height measured from the top-left point of the face,
            in pixels.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Gender">
            <summary>
            Defines values for Gender.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis">
            <summary>
            Result of AnalyzeImage operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.#ctor">
            <summary>
            Initializes a new instance of the ImageAnalysis class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.#ctor(System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Category},Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.AdultInfo,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ColorInfo,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageType,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageTag},Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescriptionDetails,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.FaceDescription},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedObject},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.DetectedBrand},System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata)">
            <summary>
            Initializes a new instance of the ImageAnalysis class.
            </summary>
            <param name="categories">An array indicating identified
            categories.</param>
            <param name="adult">An object describing whether the image contains
            adult-oriented content and/or is racy.</param>
            <param name="color">An object providing additional metadata
            describing color attributes.</param>
            <param name="imageType">An object providing possible image types
            and matching confidence levels.</param>
            <param name="tags">A list of tags with confidence level.</param>
            <param name="description">A collection of content tags, along with
            a list of captions sorted by confidence level, and image
            metadata.</param>
            <param name="faces">An array of possible faces within the
            image.</param>
            <param name="objects">Array of objects describing what was detected
            in the image.</param>
            <param name="brands">Array of brands detected in the image.</param>
            <param name="requestId">Id of the REST API request.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Categories">
            <summary>
            Gets or sets an array indicating identified categories.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Adult">
            <summary>
            Gets or sets an object describing whether the image contains
            adult-oriented content and/or is racy.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Color">
            <summary>
            Gets or sets an object providing additional metadata describing
            color attributes.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.ImageType">
            <summary>
            Gets or sets an object providing possible image types and matching
            confidence levels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Tags">
            <summary>
            Gets or sets a list of tags with confidence level.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Description">
            <summary>
            Gets or sets a collection of content tags, along with a list of
            captions sorted by confidence level, and image metadata.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Faces">
            <summary>
            Gets or sets an array of possible faces within the image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Objects">
            <summary>
            Gets or sets array of objects describing what was detected in the
            image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Brands">
            <summary>
            Gets or sets array of brands detected in the image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.RequestId">
            <summary>
            Gets or sets id of the REST API request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageAnalysis.Metadata">
            <summary>
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageCaption">
            <summary>
            An image caption, i.e. a brief description of what the image depicts.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageCaption.#ctor">
            <summary>
            Initializes a new instance of the ImageCaption class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageCaption.#ctor(System.String,System.Double)">
            <summary>
            Initializes a new instance of the ImageCaption class.
            </summary>
            <param name="text">The text of the caption.</param>
            <param name="confidence">The level of confidence the service has in
            the caption.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageCaption.Text">
            <summary>
            Gets or sets the text of the caption.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageCaption.Confidence">
            <summary>
            Gets or sets the level of confidence the service has in the
            caption.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescription">
            <summary>
            A collection of content tags, along with a list of captions sorted by
            confidence level, and image metadata.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescription.#ctor">
            <summary>
            Initializes a new instance of the ImageDescription class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescription.#ctor(System.Collections.Generic.IList{System.String},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageCaption},System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata)">
            <summary>
            Initializes a new instance of the ImageDescription class.
            </summary>
            <param name="tags">A collection of image tags.</param>
            <param name="captions">A list of captions, sorted by confidence
            level.</param>
            <param name="requestId">Id of the REST API request.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescription.Tags">
            <summary>
            Gets or sets a collection of image tags.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescription.Captions">
            <summary>
            Gets or sets a list of captions, sorted by confidence level.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescription.RequestId">
            <summary>
            Gets or sets id of the REST API request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescription.Metadata">
            <summary>
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescriptionDetails">
            <summary>
            A collection of content tags, along with a list of captions sorted by
            confidence level, and image metadata.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescriptionDetails.#ctor">
            <summary>
            Initializes a new instance of the ImageDescriptionDetails class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescriptionDetails.#ctor(System.Collections.Generic.IList{System.String},System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageCaption})">
            <summary>
            Initializes a new instance of the ImageDescriptionDetails class.
            </summary>
            <param name="tags">A collection of image tags.</param>
            <param name="captions">A list of captions, sorted by confidence
            level.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescriptionDetails.Tags">
            <summary>
            Gets or sets a collection of image tags.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageDescriptionDetails.Captions">
            <summary>
            Gets or sets a list of captions, sorted by confidence level.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata">
            <summary>
            Image metadata.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata.#ctor">
            <summary>
            Initializes a new instance of the ImageMetadata class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata.#ctor(System.Int32,System.Int32,System.String)">
            <summary>
            Initializes a new instance of the ImageMetadata class.
            </summary>
            <param name="width">Image width, in pixels.</param>
            <param name="height">Image height, in pixels.</param>
            <param name="format">Image format.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata.Width">
            <summary>
            Gets or sets image width, in pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata.Height">
            <summary>
            Gets or sets image height, in pixels.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata.Format">
            <summary>
            Gets or sets image format.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageTag">
            <summary>
            An entity observation in the image, along with the confidence score.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageTag.#ctor">
            <summary>
            Initializes a new instance of the ImageTag class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageTag.#ctor(System.String,System.Double,System.String)">
            <summary>
            Initializes a new instance of the ImageTag class.
            </summary>
            <param name="name">Name of the entity.</param>
            <param name="confidence">The level of confidence that the entity
            was observed.</param>
            <param name="hint">Optional hint/details for this tag.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageTag.Name">
            <summary>
            Gets or sets name of the entity.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageTag.Confidence">
            <summary>
            Gets or sets the level of confidence that the entity was observed.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageTag.Hint">
            <summary>
            Gets or sets optional hint/details for this tag.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageType">
            <summary>
            An object providing possible image types and matching confidence
            levels.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageType.#ctor">
            <summary>
            Initializes a new instance of the ImageType class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageType.#ctor(System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the ImageType class.
            </summary>
            <param name="clipArtType">Confidence level that the image is a clip
            art.</param>
            <param name="lineDrawingType">Confidence level that the image is a
            line drawing.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageType.ClipArtType">
            <summary>
            Gets or sets confidence level that the image is a clip art.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageType.LineDrawingType">
            <summary>
            Gets or sets confidence level that the image is a line drawing.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageUrl.#ctor">
            <summary>
            Initializes a new instance of the ImageUrl class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageUrl.#ctor(System.String)">
            <summary>
            Initializes a new instance of the ImageUrl class.
            </summary>
            <param name="url">Publicly reachable URL of an image.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageUrl.Url">
            <summary>
            Gets or sets publicly reachable URL of an image.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageUrl.Validate">
            <summary>
            Validate the object.
            </summary>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown if validation fails
            </exception>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarkResults">
            <summary>
            Result of domain-specific classifications for the domain of landmarks.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarkResults.#ctor">
            <summary>
            Initializes a new instance of the LandmarkResults class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarkResults.#ctor(System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarksModel},System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata)">
            <summary>
            Initializes a new instance of the LandmarkResults class.
            </summary>
            <param name="landmarks">List of landmarks recognized in the
            image.</param>
            <param name="requestId">Id of the REST API request.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarkResults.Landmarks">
            <summary>
            Gets or sets list of landmarks recognized in the image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarkResults.RequestId">
            <summary>
            Gets or sets id of the REST API request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarkResults.Metadata">
            <summary>
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarksModel">
            <summary>
            A landmark recognized in the image.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarksModel.#ctor">
            <summary>
            Initializes a new instance of the LandmarksModel class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarksModel.#ctor(System.String,System.Double)">
            <summary>
            Initializes a new instance of the LandmarksModel class.
            </summary>
            <param name="name">Name of the landmark.</param>
            <param name="confidence">Confidence level for the landmark
            recognition as a value ranging from 0 to 1.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarksModel.Name">
            <summary>
            Gets or sets name of the landmark.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.LandmarksModel.Confidence">
            <summary>
            Gets or sets confidence level for the landmark recognition as a
            value ranging from 0 to 1.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Line">
            <summary>
            Json object representing a recognized text line.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Line.#ctor">
            <summary>
            Initializes a new instance of the Line class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Line.#ctor(System.Collections.Generic.IList{System.Int32},System.String,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Word})">
            <summary>
            Initializes a new instance of the Line class.
            </summary>
            <param name="boundingBox">Bounding box of a recognized
            line.</param>
            <param name="text">The text content of the line.</param>
            <param name="words">List of words in the text line.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Line.BoundingBox">
            <summary>
            Gets or sets bounding box of a recognized line.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Line.Text">
            <summary>
            Gets or sets the text content of the line.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Line.Words">
            <summary>
            Gets or sets list of words in the text line.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ListModelsResult">
            <summary>
            Result of the List Domain Models operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ListModelsResult.#ctor">
            <summary>
            Initializes a new instance of the ListModelsResult class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ListModelsResult.#ctor(System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ModelDescription})">
            <summary>
            Initializes a new instance of the ListModelsResult class.
            </summary>
            <param name="modelsProperty">An array of supported models.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ListModelsResult.ModelsProperty">
            <summary>
            Gets an array of supported models.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ModelDescription">
            <summary>
            An object describing supported model by name and categories.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ModelDescription.#ctor">
            <summary>
            Initializes a new instance of the ModelDescription class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ModelDescription.#ctor(System.String,System.Collections.Generic.IList{System.String})">
            <summary>
            Initializes a new instance of the ModelDescription class.
            </summary>
            <param name="name">The name of the model.</param>
            <param name="categories">Categories of the model.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ModelDescription.Name">
            <summary>
            Gets or sets the name of the model.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ModelDescription.Categories">
            <summary>
            Gets or sets categories of the model.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ObjectHierarchy">
            <summary>
            An object detected inside an image.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ObjectHierarchy.#ctor">
            <summary>
            Initializes a new instance of the ObjectHierarchy class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ObjectHierarchy.#ctor(System.String,System.Double,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ObjectHierarchy)">
            <summary>
            Initializes a new instance of the ObjectHierarchy class.
            </summary>
            <param name="objectProperty">Label for the object.</param>
            <param name="confidence">Confidence score of having observed the
            object in the image, as a value ranging from 0 to 1.</param>
            <param name="parent">The parent object, from a taxonomy
            perspective.
            The parent object is a more generic form of this object.  For
            example, a 'bulldog' would have a parent of 'dog'.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ObjectHierarchy.ObjectProperty">
            <summary>
            Gets or sets label for the object.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ObjectHierarchy.Confidence">
            <summary>
            Gets or sets confidence score of having observed the object in the
            image, as a value ranging from 0 to 1.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ObjectHierarchy.Parent">
            <summary>
            Gets or sets the parent object, from a taxonomy perspective.
            The parent object is a more generic form of this object.  For
            example, a 'bulldog' would have a parent of 'dog'.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLanguages">
            <summary>
            Defines values for OcrLanguages.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLine">
            <summary>
            An object describing a single recognized line of text.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLine.#ctor">
            <summary>
            Initializes a new instance of the OcrLine class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLine.#ctor(System.String,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrWord})">
            <summary>
            Initializes a new instance of the OcrLine class.
            </summary>
            <param name="boundingBox">Bounding box of a recognized line. The
            four integers represent the x-coordinate of the left edge, the
            y-coordinate of the top edge, width, and height of the bounding
            box, in the coordinate system of the input image, after it has been
            rotated around its center according to the detected text angle (see
            textAngle property), with the origin at the top-left corner, and
            the y-axis pointing down.</param>
            <param name="words">An array of objects, where each object
            represents a recognized word.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLine.BoundingBox">
            <summary>
            Gets or sets bounding box of a recognized line. The four integers
            represent the x-coordinate of the left edge, the y-coordinate of
            the top edge, width, and height of the bounding box, in the
            coordinate system of the input image, after it has been rotated
            around its center according to the detected text angle (see
            textAngle property), with the origin at the top-left corner, and
            the y-axis pointing down.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLine.Words">
            <summary>
            Gets or sets an array of objects, where each object represents a
            recognized word.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrRegion">
            <summary>
            A region consists of multiple lines (e.g. a column of text in a
            multi-column document).
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrRegion.#ctor">
            <summary>
            Initializes a new instance of the OcrRegion class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrRegion.#ctor(System.String,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrLine})">
            <summary>
            Initializes a new instance of the OcrRegion class.
            </summary>
            <param name="boundingBox">Bounding box of a recognized region. The
            four integers represent the x-coordinate of the left edge, the
            y-coordinate of the top edge, width, and height of the bounding
            box, in the coordinate system of the input image, after it has been
            rotated around its center according to the detected text angle (see
            textAngle property), with the origin at the top-left corner, and
            the y-axis pointing down.</param>
            <param name="lines">An array of recognized lines of text.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrRegion.BoundingBox">
            <summary>
            Gets or sets bounding box of a recognized region. The four integers
            represent the x-coordinate of the left edge, the y-coordinate of
            the top edge, width, and height of the bounding box, in the
            coordinate system of the input image, after it has been rotated
            around its center according to the detected text angle (see
            textAngle property), with the origin at the top-left corner, and
            the y-axis pointing down.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrRegion.Lines">
            <summary>
            Gets or sets an array of recognized lines of text.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrResult.#ctor">
            <summary>
            Initializes a new instance of the OcrResult class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrResult.#ctor(System.String,System.Double,System.String,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrRegion})">
            <summary>
            Initializes a new instance of the OcrResult class.
            </summary>
            <param name="language">The BCP-47 language code of the text in the
            image.</param>
            <param name="textAngle">The angle, in degrees, of the detected text
            with respect to the closest horizontal or vertical direction. After
            rotating the input image clockwise by this angle, the recognized
            text lines become horizontal or vertical. In combination with the
            orientation property it can be used to overlay recognition results
            correctly on the original image, by rotating either the original
            image or recognition results by a suitable angle around the center
            of the original image. If the angle cannot be confidently detected,
            this property is not present. If the image contains text at
            different angles, only part of the text will be recognized
            correctly.</param>
            <param name="orientation">Orientation of the text recognized in the
            image. The value (up, down, left, or right) refers to the direction
            that the top of the recognized text is facing, after the image has
            been rotated around its center according to the detected text angle
            (see textAngle property).</param>
            <param name="regions">An array of objects, where each object
            represents a region of recognized text.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrResult.Language">
            <summary>
            Gets or sets the BCP-47 language code of the text in the image.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrResult.TextAngle">
            <summary>
            Gets or sets the angle, in degrees, of the detected text with
            respect to the closest horizontal or vertical direction. After
            rotating the input image clockwise by this angle, the recognized
            text lines become horizontal or vertical. In combination with the
            orientation property it can be used to overlay recognition results
            correctly on the original image, by rotating either the original
            image or recognition results by a suitable angle around the center
            of the original image. If the angle cannot be confidently detected,
            this property is not present. If the image contains text at
            different angles, only part of the text will be recognized
            correctly.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrResult.Orientation">
            <summary>
            Gets or sets orientation of the text recognized in the image. The
            value (up, down, left, or right) refers to the direction that the
            top of the recognized text is facing, after the image has been
            rotated around its center according to the detected text angle (see
            textAngle property).
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrResult.Regions">
            <summary>
            Gets or sets an array of objects, where each object represents a
            region of recognized text.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrWord">
            <summary>
            Information on a recognized word.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrWord.#ctor">
            <summary>
            Initializes a new instance of the OcrWord class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrWord.#ctor(System.String,System.String)">
            <summary>
            Initializes a new instance of the OcrWord class.
            </summary>
            <param name="boundingBox">Bounding box of a recognized word. The
            four integers represent the x-coordinate of the left edge, the
            y-coordinate of the top edge, width, and height of the bounding
            box, in the coordinate system of the input image, after it has been
            rotated around its center according to the detected text angle (see
            textAngle property), with the origin at the top-left corner, and
            the y-axis pointing down.</param>
            <param name="text">String value of a recognized word.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrWord.BoundingBox">
            <summary>
            Gets or sets bounding box of a recognized word. The four integers
            represent the x-coordinate of the left edge, the y-coordinate of
            the top edge, width, and height of the bounding box, in the
            coordinate system of the input image, after it has been rotated
            around its center according to the detected text angle (see
            textAngle property), with the origin at the top-left corner, and
            the y-axis pointing down.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.OcrWord.Text">
            <summary>
            Gets or sets string value of a recognized word.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ReadOperationResult">
            <summary>
            OCR result of the read operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ReadOperationResult.#ctor">
            <summary>
            Initializes a new instance of the ReadOperationResult class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ReadOperationResult.#ctor(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationStatusCodes,System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult})">
            <summary>
            Initializes a new instance of the ReadOperationResult class.
            </summary>
            <param name="status">Status of the read operation. Possible values
            include: 'Not Started', 'Running', 'Failed', 'Succeeded'</param>
            <param name="recognitionResults">A array of text recognition result
            of the read operation.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ReadOperationResult.Status">
            <summary>
            Gets or sets status of the read operation. Possible values include:
            'Not Started', 'Running', 'Failed', 'Succeeded'
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ReadOperationResult.RecognitionResults">
            <summary>
            Gets or sets a array of text recognition result of the read
            operation.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.RecognizeTextHeaders">
            <summary>
            Defines headers for RecognizeText operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.RecognizeTextHeaders.#ctor">
            <summary>
            Initializes a new instance of the RecognizeTextHeaders class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.RecognizeTextHeaders.#ctor(System.String)">
            <summary>
            Initializes a new instance of the RecognizeTextHeaders class.
            </summary>
            <param name="operationLocation">URL to query for status of the
            operation. The operation ID will expire in 48 hours. </param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.RecognizeTextHeaders.OperationLocation">
            <summary>
            Gets or sets URL to query for status of the operation. The
            operation ID will expire in 48 hours.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.RecognizeTextInStreamHeaders">
            <summary>
            Defines headers for RecognizeTextInStream operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.RecognizeTextInStreamHeaders.#ctor">
            <summary>
            Initializes a new instance of the RecognizeTextInStreamHeaders
            class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.RecognizeTextInStreamHeaders.#ctor(System.String)">
            <summary>
            Initializes a new instance of the RecognizeTextInStreamHeaders
            class.
            </summary>
            <param name="operationLocation">URL to query for status of the
            operation. The operation ID will expire in 48 hours. </param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.RecognizeTextInStreamHeaders.OperationLocation">
            <summary>
            Gets or sets URL to query for status of the operation. The
            operation ID will expire in 48 hours.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TagResult">
            <summary>
            The results of a image tag operation, including any tags and image
            metadata.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TagResult.#ctor">
            <summary>
            Initializes a new instance of the TagResult class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TagResult.#ctor(System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageTag},System.String,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.ImageMetadata)">
            <summary>
            Initializes a new instance of the TagResult class.
            </summary>
            <param name="tags">A list of tags with confidence level.</param>
            <param name="requestId">Id of the REST API request.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TagResult.Tags">
            <summary>
            Gets or sets a list of tags with confidence level.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TagResult.RequestId">
            <summary>
            Gets or sets id of the REST API request.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TagResult.Metadata">
            <summary>
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationResult">
            <summary>
            Result of recognition text operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationResult.#ctor">
            <summary>
            Initializes a new instance of the TextOperationResult class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationResult.#ctor(Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationStatusCodes,Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult)">
            <summary>
            Initializes a new instance of the TextOperationResult class.
            </summary>
            <param name="status">Status of the text operation. Possible values
            include: 'Not Started', 'Running', 'Failed', 'Succeeded'</param>
            <param name="recognitionResult">Text recognition result of the text
            operation.</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationResult.Status">
            <summary>
            Gets or sets status of the text operation. Possible values include:
            'Not Started', 'Running', 'Failed', 'Succeeded'
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationResult.RecognitionResult">
            <summary>
            Gets or sets text recognition result of the text operation.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationResult.Validate">
            <summary>
            Validate the object.
            </summary>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown if validation fails
            </exception>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextOperationStatusCodes">
            <summary>
            Defines values for TextOperationStatusCodes.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionMode">
            <summary>
            Defines values for TextRecognitionMode.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult">
            <summary>
            Json object representing a recognized text region
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.#ctor">
            <summary>
            Initializes a new instance of the TextRecognitionResult class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.#ctor(System.Collections.Generic.IList{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Line},System.Nullable{System.Int32},System.Nullable{System.Double},System.Nullable{System.Double},System.Nullable{System.Double},System.Nullable{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResultDimensionUnit})">
            <summary>
            Initializes a new instance of the TextRecognitionResult class.
            </summary>
            <param name="lines">A list of recognized text lines.</param>
            <param name="page">The 1-based page number of the recognition
            result.</param>
            <param name="clockwiseOrientation">The orientation of the image in
            degrees in the clockwise direction. Range between [0, 360).</param>
            <param name="width">The width of the image in pixels or the PDF in
            inches.</param>
            <param name="height">The height of the image in pixels or the PDF
            in inches.</param>
            <param name="unit">The unit used in the Width, Height and
            BoundingBox. For images, the unit is "pixel". For PDF, the unit is
            "inch". Possible values include: 'pixel', 'inch'</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.Page">
            <summary>
            Gets or sets the 1-based page number of the recognition result.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.ClockwiseOrientation">
            <summary>
            Gets or sets the orientation of the image in degrees in the
            clockwise direction. Range between [0, 360).
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.Width">
            <summary>
            Gets or sets the width of the image in pixels or the PDF in inches.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.Height">
            <summary>
            Gets or sets the height of the image in pixels or the PDF in
            inches.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.Unit">
            <summary>
            Gets or sets the unit used in the Width, Height and BoundingBox.
            For images, the unit is "pixel". For PDF, the unit is "inch".
            Possible values include: 'pixel', 'inch'
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.Lines">
            <summary>
            Gets or sets a list of recognized text lines.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResult.Validate">
            <summary>
            Validate the object.
            </summary>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown if validation fails
            </exception>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResultConfidenceClass">
            <summary>
            Defines values for TextRecognitionResultConfidenceClass.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResultDimensionUnit">
            <summary>
            Defines values for TextRecognitionResultDimensionUnit.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.VisualFeatureTypes">
            <summary>
            Defines values for VisualFeatureTypes.
            </summary>
        </member>
        <member name="T:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Word">
            <summary>
            Json object representing a recognized word.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Word.#ctor">
            <summary>
            Initializes a new instance of the Word class.
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Word.#ctor(System.Collections.Generic.IList{System.Int32},System.String,System.Nullable{Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.TextRecognitionResultConfidenceClass})">
            <summary>
            Initializes a new instance of the Word class.
            </summary>
            <param name="boundingBox">Bounding box of a recognized
            word.</param>
            <param name="text">The text content of the word.</param>
            <param name="confidence">Qualitative confidence measure. Possible
            values include: 'High', 'Low'</param>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Word.BoundingBox">
            <summary>
            Gets or sets bounding box of a recognized word.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Word.Text">
            <summary>
            Gets or sets the text content of the word.
            </summary>
        </member>
        <member name="P:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Word.Confidence">
            <summary>
            Gets or sets qualitative confidence measure. Possible values
            include: 'High', 'Low'
            </summary>
        </member>
        <member name="M:Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models.Word.Validate">
            <summary>
            Validate the object.
            </summary>
            <exception cref="T:Microsoft.Rest.ValidationException">
            Thrown if validation fails
            </exception>
        </member>
    </members>
</doc>
